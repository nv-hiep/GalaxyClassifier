{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"galaxy_classifier.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyOjD6AgUK/hdsbeimDn7lB8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"twluDsqOaqRW"},"source":["**Open this notebook from google drive**<br>\n","**Go to \"Edit\" -> \"Notebook settings\" and enable GPU.**\n"]},{"cell_type":"code","metadata":{"id":"srBiJiFEaKl1"},"source":["# Check if NVIDIA GPU is enabled\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sj3eAw1OXOnB"},"source":["**Connect and authorize google drive with google colab:**"]},{"cell_type":"code","metadata":{"id":"PjjcQSpya_FR"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h5GywMhIKCd0"},"source":["**Open our project \"Galaxy Classifier\" direct0ry in google drive:**"]},{"cell_type":"code","metadata":{"id":"iYM4wmy-cFlK"},"source":["# %cd /content/gdrive/My Drive/\n","%cd /content/gdrive/My Drive/Colab Notebooks/galaxy_classifier/\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O7CYSllU-tyf"},"source":["**Data for our \"Galaxy Classifier\" directory in google drive:**"]},{"cell_type":"code","metadata":{"id":"zbtyUhYA_AxZ"},"source":["%cd /content/gdrive/My Drive/data/galaxy_data/\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"24u5FY2ZKbrc"},"source":["**Install all required libraries for our project:**"]},{"cell_type":"code","metadata":{"id":"adhpOaKT9lWC"},"source":["# !pip install -r ./requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3cWo7hhc-qO"},"source":["import os, random, shutil\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline  \n","\n","import tensorflow as tf\n","print(tf.__version__)\n","tf.test.gpu_device_name()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DDmBbAUKLUkB"},"source":["**Test if TensorFlow works with gpu for you, in output should see similar results:**\n","```\n","2.2.0\n","'/device:GPU:0'\n","```"]},{"cell_type":"code","metadata":{"id":"Z9d185J9_xQZ"},"source":["current_dir = os.getcwd()\n","print(current_dir)\n","\n","data_path    = '/content/gdrive/My Drive/data/galaxy_data'\n","training_dir = os.path.join(data_path, 'training')\n","valid_dir    = os.path.join(data_path, 'validation')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-5r2CqsBEiL"},"source":["# Get the total images in the training and validation dataset, this should be around 8619 images for training, and 2875 for validation.\n","total_train = 0\n","for c in ['elliptical', 'lenticular', 'spiral']:\n","  total_train += len(os.listdir(os.path.join(training_dir, c)))\n","print('Total train:', total_train)\n","\n","total_validation = 0\n","for c in ['elliptical', 'lenticular', 'spiral']:\n","  total_validation += len(os.listdir(os.path.join(valid_dir, c)))\n","print('Total validation:', total_validation)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"js-AVsr_BsI5"},"source":["dir_augmented_data = os.path.join(data_path, 'preview')\n","try:\n","    ## if the preview folder does not exist, create\n","    os.mkdir(dir_augmented_data)\n","except:\n","    ## if the preview folder exists, then remove\n","    ## the contents (pictures) in the folder\n","    for item in os.listdir(dir_augmented_data):\n","        os.remove(dir_augmented_data + \"/\" + item)\n","\n","\n","# Resize the images to (64, 64) pixels\n","target_size = (150, 150)\n","\n","# Set the batch size.\n","batch_size = 32\n","\n","# Color channels\n","color_channels = 3\n","\n","\n","# Create the data generator for both sets, but now with image augmentation,\n","# where random operations are made on images like random shifts or rotationson each batch,\n","# stil do the rescale and set the target size.\n","\n","# datagen for training set\n","train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","                    rescale            = 1./255.,\n","                    rotation_range     = 25,\n","                    width_shift_range  = 0.15,\n","                    height_shift_range = 0.15,\n","                    horizontal_flip    = True,\n","                    zoom_range         = 0.2)\n","\n","\n","train_generator = train_datagen.flow_from_directory(training_dir,\n","                                                    target_size = target_size,\n","                                                    batch_size  = batch_size,\n","                                                    shuffle     = True,\n","                                                    class_mode  = 'categorical')\n","\n","\n","# datagen for validation set\n","validation_datagen  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.)\n","validation_generator = validation_datagen.flow_from_directory(valid_dir,\n","                                                         target_size = target_size,\n","                                                         batch_size  = batch_size,\n","                                                         shuffle     = False,\n","                                                         class_mode  = 'categorical')\n","\n","allclasses = train_generator.class_indices    \n","print(allclasses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWZbSskHDCRL"},"source":["# To see what's going on this data augmentation, run the following\n","if(False):\n","  i = 0\n","  for batch in train_datagen.flow_from_directory(training_dir,\n","      target_size = target_size, batch_size  = batch_size,\n","      save_to_dir = dir_augmented_data, save_prefix = 'pic', save_format = 'png',\n","      color_mode = 'grayscale', shuffle = True, class_mode  = 'categorical'):\n","\n","      i += 1\n","      if i > 5: # save 20 images\n","          break  # otherwise the generator would loop indefinitely"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7UwZ1nelD3XB"},"source":["**The model**"]},{"cell_type":"code","metadata":{"id":"unuFSoz9D2zd"},"source":["# Create the model, using a sequence of convolution and pooling layers,\n","# followed by a dropout layer, a fully connected layer, and the last softmax layer.\n","\n","# Xem: https://forum.machinelearningcoban.com/t/tutorial-tinh-so-luong-parameters-trong-convolutional-neural-network/3638\n","\n","\n","model = tf.keras.models.Sequential([\n","    # first convolution layer, input is an 64x64 image x3 colors\n","    # 64 filters, with a size of (3x3) for each filter (each filter has 3x3 = 9 weights)\n","    # e.g: input = 28x28 pixels\n","    #      kernel filter = (3,3)\n","    #      No. of filters: 32\n","    #     -> Output of Conv2D layer: (28 x 28 x 32)\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu',\n","                           input_shape=(target_size[0],target_size[1], color_channels)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    \n","    # second convolution layer\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n","    # third convolution layer\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n","    # fourth convolution layer\n","    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    \n","    # flatten the image pixels\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    \n","    # 512 neuron fully connected hidden layer\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(3, activation='softmax')\n","])\n","\n","model.summary()  # inspect model\n","\n","\n","# Compile the model to use a categorical cross entropy loss function, and a adam optmizier.\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-4AmqaAERs0"},"source":["**Train the model**"]},{"cell_type":"code","metadata":{"id":"JzHZpxkdEQYZ"},"source":["# Train the model for 100 epochs.\n","EPOCHS = 100\n","\n","# Train the model here\n","history = model.fit(train_generator,\n","                    epochs          = EPOCHS,\n","                    validation_data = validation_generator,\n","                    verbose         = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGGosCyAZxOT"},"source":["import pickle\n","print(data_path + '/train_hist_dict.pkl')\n","with open(data_path + '/train_hist_dict.pkl', 'wb') as file_hist:\n","        pickle.dump(history.history, file_hist)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mdrdAAe7EY-P"},"source":["**Finish training -> plot graphs**"]},{"cell_type":"code","metadata":{"id":"JmehHs96EZZ_"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(len(acc))  # range for the number of epochs\n","\n","plt.figure(figsize=(16, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.savefig(data_path + '/plots.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1kNbUvFLEge9"},"source":["**Save the trained model**"]},{"cell_type":"code","metadata":{"id":"EEq7g0wZEjiP"},"source":["model.save(data_path + '/galaxy_convnet_rgb.h5')"],"execution_count":null,"outputs":[]}]}